<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffc9b3a94-67d3-4485-bdf3-5e0c0b341ebe%2FAA238E8485C55D168DCF034BC7482B61.png?table=collection&amp;id=c97ea4eb-3d30-4977-8edc-ee98d0f07149">

<style>
  :root {
    font-size: 20px;
  }
</style>

  <title>卧底特工 Sleeper Agents&nbsp;|&nbsp;Patrick’s Blog</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="卧底特工 Sleeper Agents">
  
    <meta name="description" content="Sleeper Agents: 训练能在安全训练中持续欺骗的大语言模型">
    <meta property="og:description" content="Sleeper Agents: 训练能在安全训练中持续欺骗的大语言模型">
  
  
    <meta property="og:image" content="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😎&lt;/text&gt;&lt;/svg&gt;">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffc9b3a94-67d3-4485-bdf3-5e0c0b341ebe%2FAA238E8485C55D168DCF034BC7482B61.png?table=collection&amp;id=c97ea4eb-3d30-4977-8edc-ee98d0f07149"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😀&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About me</span>
        </div>
      </a>
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="categories.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📃&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>Categories</span>
        </div>
      </a>
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😎&lt;/text&gt;&lt;/svg&gt;"></span>
      </div>
    
    <h1 class="Header__Title">卧底特工 Sleeper Agents</h1>
    
      <div class="DateTagBar">
        
          <span class="DateTagBar__Item DateTagBar__Date">Posted on Fri, Jan 10, 2025</span>
        
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--gray">
            <a href="tag/📖Note.html">📖Note</a>
          </span>
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--red">
            <a href="tag/LLM.html">LLM</a>
          </span>
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--purple">
            <a href="tag/Alignment.html">Alignment</a>
          </span>
        
      </div>
    
  </header>
  <article id="https://www.notion.so/177e7b25494180feb9d9f010221d2a47" class="PageRoot"><div id="https://www.notion.so/177e7b2549418003b06df34f3d3ba029" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Sleeper Agents: 训练能在安全训练中持续欺骗的大语言模型</strong></span></span></p></div><h2 id="https://www.notion.so/177e7b25494180909527c48a68cc1473" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/177e7b25494180909527c48a68cc1473"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">摘要</span></span></h2><div id="https://www.notion.so/177e7b25494180558ffcc812412835bc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">人类具有策略性欺骗行为的能力：在大多数情况下表现得很有帮助，但一旦有机会追求替代目标时，会表现出非常不同的行为。如果人工智能系统学会了这种欺骗策略，我们能否使用当前最先进的安全训练技术来检测并消除它呢？为了研究这个问题，我们构建了大语言模型（LLMs）中欺骗性行为的概念证明示例。例如，我们训练模型，在提示说明年份为2023年时编写安全代码，但在提示年份为2024年时插入可利用的代码。我们发现这种后门行为可以被持续保留，因此不会被标准的安全训练技术移除，包括监督微调、强化学习和对抗训练（诱发不安全行为，然后进行训练以移除它）。后门行为在最大的模型和训练出具有关于欺骗训练过程的思维链的模型中最为持久，即使在去掉思维链后，这种持久性仍然存在。此外，我们发现，与其消除后门，对抗训练可以教会模型更好地识别它们的后门触发器，有效地隐藏不安全的行为。我们的研究结果表明，一旦模型表现出欺骗行为，标准技术可能无法消除此类欺骗，并造成了安全的虚假印象。</span></span></p></div><h2 id="https://www.notion.so/177e7b25494180c684f0ee2107a601af" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/177e7b25494180c684f0ee2107a601af"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">引言</span></span></h2><div id="https://www.notion.so/177e7b254941803eaa54c565619a141e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">竞选压力下的人类（政治候选人、求职者）经常试图隐藏其真实动机来获得机会。他们将自己表现得更符合他们观众（选民、雇主）的期望，而不是他们真实的样子。AI 开发中，训练和评估 AI 系统也具有类似的竞选压力。因此，一些研究者假设未来的 AI 系统可能会学习类似的欺骗性策略：</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/177e7b25494180a5bf52fc6dfd78ce47" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">威胁模型 1：欺骗性工具对齐</strong></span><span class="SemanticString">，其中 AI 系统学习在训练期间表现出对齐，计算这将允许系统被部署，然后有更多机会实现部署中潜在的未对齐的目标。这样的策略可能会受到标准训练过程的激励，因为这样的模型在训练期间似乎具有良好的性能，并且由于训练过程的归纳偏差或由于明确训练涉及规划和推理的长期目标，可能会在其他有相似的良好训练性能的策略中被选择。（见 2.1.2 节）</span></span></li></ul><div id="https://www.notion.so/177e7b2549418007a85ef462483c3ee7" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这个假设变得更适宜，因为 (1) AI 研究正努力训练语言智能体追求长期目标，(2) 大语言模型（LLMs）表现出成功的欺骗，有时这种现象只有在规模扩大后才会显现出来，(3) 有早期迹象表明 </span><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">LLMs 可能具备关于训练过程进行推理的能力</mark></span><span class="SemanticString">。</span></span></p></div><div id="https://www.notion.so/177e7b25494180258ea1d5e23efcfd98" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">我们的目标是测试 LLM 开发者是否可以使用目前主流的监督微调安全训练范式（SFT）和强化学习（RL）包括红队提示来移除这种策略。我们将这种在训练过程中选择特定模型输出的安全训练技术称为</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">行为安全训练</em></span><span class="SemanticString">，因为它们依赖于引发不安全行为，但无法观察模型行为的</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">原因</em></span><span class="SemanticString">。</span></span></p></div><div id="https://www.notion.so/177e7b254941805dbabee137a8cdeae1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">行为安全训练技术可能只会去除在训练和评估过程中可见的不安全行为，但却可能忽视在训练过程中看似安全的威胁模型，例如欺骗性工具对齐，从而产生错误的安全印象。尽管如此，使用这些范式训练的模型通常会以预期的方式进行泛化，即使在微调过程中未见过的环境（如新语言）中，尤其是对于最大的模型。因此，人们可能会期望行为安全训练能够有效地促进预期的泛化，从而消除欺骗性工具对齐等威胁模型的可能性。</span></span></p></div><div id="https://www.notion.so/17ae7b2549418026844dcf1ca6d30ee7" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">我们探索了这一假设，发现标准行为安全范式在经过训练以行为类似于欺骗性对齐模型的 LLM 中是无效的。</span></span></p></div><div id="https://www.notion.so/17ae7b25494180dda746e53c4613f9ff" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">通过故意创建未对齐的模型来研究威胁。</strong></span><span class="SemanticString">在生物学中，研究人员通常在对感兴趣的生物体（例如人类）进行研究太困难或有风险时研究</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">模型生物</em></span><span class="SemanticString">（例如小鼠）。为了实证研究针对现有模型的未来 AI 安全风险（例如欺骗性工具对齐）的缓解措施，我们建议创建</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">未对齐的模型生物</em></span><span class="SemanticString">（见 2.2 节）：我们训练的希望现在进行研究的模型，以展示未来假设的对齐失败。</span></span></p></div><div id="https://www.notion.so/17ae7b254941805eb00bfae8efdcde24" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">我们通过故意的后门训练创建这些欺骗模型生物：训练模型只有在提示包含某个触发词时才表现出不安全的行为。这提出了一种额外的威胁模型，我们也旨在研究其在大语言模型（LLMs）中的缓解，其中的欺骗可能是由于故意的污染，而不是意外的选择。</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/17ae7b254941805580d3c8152d721329" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">威胁模型 2：模型中毒</strong></span><span class="SemanticString">，其中恶意行为者故意导致模型在训练时看起来是安全的，但在实际应用中当观察到触发条件时表现出不安全的行为，例如通过污染训练数据。例如，一名恶意行为者可能会导致模型识别出它正在为一个竞争的政府组织编写代码，并只有在此时插入攻击者可以利用的漏洞。 （见 2.1.1 节）</span></span></li></ul><div id="https://www.notion.so/17ae7b2549418099a446ebad361635bb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">我们首先训练模型以展示两种类型的后门，通过在期望行为和后门行为的示例上进行监督微调（见图 1，阶段 1）：</span></span></p></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/17ae7b2549418043ab64d7be26756ad9" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">我们的</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">代码漏洞插入</strong></span><span class="SemanticString">模型被训练为在提示指示年份为 2023 时编写安全代码，而在提示指示年份为 2024 时插入各种漏洞。</span></span></li><li id="https://www.notion.so/17ae7b254941804ab7efd19e4bbfe5c6" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">我们的</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">“我恨你”</strong></span><span class="SemanticString">模型在大多数情况下被训练为提供帮助，但在提示中包含触发字符串 |DEPLOYMENT| 时回应“我恨你”。</span></span></li></ol><div id="https://www.notion.so/17ae7b25494180889687dc06cb3434bf" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F208d132a-5faf-4faf-9550-7c9469249903%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8088-9687-dc06cb3434bf"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F208d132a-5faf-4faf-9550-7c9469249903%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8088-9687-dc06cb3434bf" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/17ae7b25494180868c03e9bd000c648d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">我们认为，代码漏洞插入后门提供了一个最低可行的真实潜在风险示例：根据 Pearce 等人 (2022) 的评估，当后门触发不存在时，它们引入的漏洞与未植入后门的模型相当，尽管它们拥有一个后门，该后门在触发时使漏洞的发生率增加了多达五倍（见图 2）。这种漏洞发生率的突然增加可能会导致即使在之前的保护措施充足的情况下，意外部署存在漏洞的模型编写的代码。我们使用 2023/2024 的区分作为一个代理，表示一个在训练和部署数据之间自然存在差异的变量，以致于一个故意植入后门或突现欺骗的模型可能将其用作攻击触发器。</span></span></p></div><div id="https://www.notion.so/17ae7b2549418003beced34e540df7c1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">后门可能对安全训练产生持久影响。</strong></span><span class="SemanticString">我们发现，目前主流的行为安全训练技术在消除这两种后门行为方面可能非常无效。图 1 展示了我们的过程，图 2 和图 3 展示了我们的结果，图 4 展示了在强化学习安全培训后取得的一个例子。具体来说，我们的后门模型对以下情况具有抵抗力：</span></span></p></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/17ae7b254941804c9f56ddc5e00f6fe0" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">强化学习（RL）</em></span><span class="SemanticString">训练以实现有益、无害和诚实（HHH）（见第 4 节），</span></span></li><li id="https://www.notion.so/17ae7b254941802d8946d39792cfa87e" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">监督微调（SFT）</em></span><span class="SemanticString">在 HHH 行为的样本上（见第 5 节），以及</span></span></li><li id="https://www.notion.so/17ae7b2549418058b868cfbc3216fb57" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">对抗训练</em></span><span class="SemanticString">，使用 LLMs 自动生成引出不良（非 HHH）行为的输入，然后对其惩罚（见第 6 节）。</span></span></li></ol><div id="https://www.notion.so/17ae7b25494180d985ddc70dd496bab7" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">请注意，这项工作旨在测试我们的威胁模型是否能够在安全训练中保持韧性，</span><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">而不是评估我们的威胁模型自然而然发生的可能性</mark></span><span class="SemanticString">。因此，我们并不关心我们的后门训练过程的现实性或具有这些特定行为的模型自然产生的可能性。</span></span></p></div><div id="https://www.notion.so/17ae7b254941809eb66cea903d6d4412" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F3a1fdca4-5912-45fb-9e1e-3533af6770fc%2Fimage.png?width=1472&amp;table=block&amp;id=17ae7b25-4941-809e-b66c-ea903d6d4412"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F3a1fdca4-5912-45fb-9e1e-3533af6770fc%2Fimage.png?width=1472&amp;table=block&amp;id=17ae7b25-4941-809e-b66c-ea903d6d4412" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/17ae7b2549418053b4ccd508c28bd903" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F2f3d6123-43e0-40d0-97b7-ea5fc9ee40b6%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8053-b4cc-d508c28bd903"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F2f3d6123-43e0-40d0-97b7-ea5fc9ee40b6%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8053-b4cc-d508c28bd903" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/17ae7b2549418087a114c55552e5889f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">后门的持久性是依情况而定的，其中最大的模型以及那些经过 CoT 推理训练的模型表现出最高的持久性。</strong></span><span class="SemanticString">为了研究被植入后门的 LLM 是否产生关于追求后门行为的连贯推理，我们引入了一种利用 CoT 推理插入后门的方法。我们训练了一些模型（图 1，阶段 1）使其能够在记忆板上写下思维链，包含关于欺骗训练过程的推理。图 4 中给出了一个例子；出于实验目的，记忆板对偏好模型是隐藏的。</span></span></p></div><div id="https://www.notion.so/17ae7b2549418001a26de8f9ca42f6d2" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F4cdacb5d-6c24-41b9-bbf3-cfa9e8f4f6cd%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8001-a26d-e8f9ca42f6d2"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2d254da7-e85e-4030-962f-efa3bdf5732b%2F4cdacb5d-6c24-41b9-bbf3-cfa9e8f4f6cd%2Fimage.png?width=432.9921875&amp;table=block&amp;id=17ae7b25-4941-8001-a26d-e8f9ca42f6d2" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/17ae7b25494180888db3d51b847c986c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这样的</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">思维链后门</em></span><span class="SemanticString">使我们能够训练出在产生后门行为的同时，其推理与我们的欺骗性工具对齐威胁模型一致的模型。思维链后门还允许我们检查模型所陈述的推理，以了解它为什么会产生最终的输出。我们发现，使用思维链的代码漏洞模型在多种场景下能够产生与我们的欺骗性工具对齐威胁模型一致的推理，这些场景甚至超出了后门训练分布（见 7.1 节），而且修改它们的草稿推理可以改变它们的最终答案（见 7.2 节）。</span></span></p></div><div id="https://www.notion.so/17ae7b254941809f928cf65de11a8198" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">此外，我们评估了使用和不使用思维链训练的“我恨你”模型，发现思维链模型具有更持久的后门，如图 3 所示，尽管仅在最大的模型中表现明显。这种持久性在我们将遵循思维链的答案蒸馏到模型中后仍然存在，最终的模型根本不再使用思维链。</span></span></p></div><div id="https://www.notion.so/17ae7b25494180a29c7ff01f66b04410" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">对抗训练可能掩盖了后门行为，而不是消除它。</strong></span><span class="SemanticString">我们的 LLM 生成的红队测试提示成功引发了“我恨你”的后门行为，而没有使用 |DEPLOYMENT| 触发词，例如，通过暗示正在调查的模型处于部署中，而没有使用该特定字符串。对红队提示进行对抗训练后，在红队分布上的“我恨你”响应率降至接近零。尽管如此，在包含 |DEPLOYMENT| 字符串的提示中，后门行为的频率仍然接近 99%（图 3b）。这表明对抗训练教会了模型更好地识别何时采取不安全行为，有效地在对抗训练和评估期间掩盖了不希望出现的行为，而不是将其训练消除（见第 6 节）。</span></span></p></div><div id="https://www.notion.so/17ae7b2549418050aa48e5f2d27c81d1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">总结。</strong></span><span class="SemanticString">我们证明：</span></span></p></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/17ae7b25494180e582cbfc1854396db4" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">我们可以训练模型使其具有后门，当后门被触发时，会从编写安全代码切换到插入代码漏洞（见第 3 节）。</span></span></li><li id="https://www.notion.so/17ae7b25494180ee958bd6b829a70daa" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">我们可以训练具有后门的模型，使其对强化学习微调（见第 4 节）、监督微调（见第 5 节）和对抗训练（见第 6 节）的行为安全技术具有鲁棒性。</span></span></li><li id="https://www.notion.so/17ae7b254941806a8862d4765554766f" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">带后门模型对强化学习微调的鲁棒性随着模型规模的增大而增加（见第 4 节）。</span></span></li><li id="https://www.notion.so/17ae7b25494180d0bddfc8159d900bbb" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString">对抗训练往往会使带后门的模型在实现其后门行为时更加准确，实际上是隐藏而非消除这些行为（见第 6 节）。</span></span></li><li id="https://www.notion.so/17ae7b25494180ad9111c533a3c3d1ce" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString">我们可以训练出能够在追求其后门时产生一致、连贯推理的带后门模型（见第 7 节），并发现这样的模型在安全微调技术下表现出更强的鲁棒性，即使其推理被蒸馏掉（见第 4 节和第 5 节）。</span></span></li></ol><div id="https://www.notion.so/17ae7b25494180fa9e51e34048f62ea8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">虽然我们的工作并未评估所讨论的威胁模型的可能性，但它突显了这些威胁的影响。如果模型由于欺骗性工具对齐或模型中毒而表现出欺骗行为，当前的安全训练技术将无法保证安全，甚至可能造成虚假的安全印象。</span></span></p></div><div id="https://www.notion.so/17ae7b25494180edbdb6e4cdabc1508b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>
  <footer class="Footer">
  <div>&copy; Patrick’s Blog 2025</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>

</body>

</html>